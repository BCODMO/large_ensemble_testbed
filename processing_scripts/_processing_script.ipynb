{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing script\n",
    "This script (1.) calculates CO2 flux for each member, (2.) calculates a suite of statistics on each member, and (3.) decomposes the flux into various time scales. \n",
    "Processing is done with [DASK](https://docs.dask.org/en/latest/) to speed up computation. \n",
    "\n",
    "### 1. calculate flux\n",
    "air-sea CO2 exchange is parameterized following Wanninkhof (1992) with Sweeney et al. (2007) gas-exchange coefficient scaled to match ERA interim winds. \n",
    "\n",
    "### 2. calculate statistics\n",
    "Statistical metrics used in this analysis. Metrics are calculated seprately for each member and the average across all ensemble members is displayed. \n",
    "- Bias : measures long-term offset\n",
    "- correlation : measures phasing\n",
    "- normalized STD : measure of amplitude\n",
    "\n",
    "### 3. decompose_flux\n",
    "This function decomposes the CO2 flux into various time scales:\n",
    "- detrended\n",
    "- IAV\n",
    "- AV\n",
    "- decadal\n",
    "- subdecadal\n",
    "\n",
    "## References \n",
    "- Wanninkhof (1992)\n",
    "- Sweeney et al. (2007)\n",
    "- Weiss (1974)\n",
    "- Dickson et al. (2007)\n",
    "- Landschutzer et al. (2016)\n",
    "- Stow et al. (2009)\n",
    "- ERA interim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Start the DASK client\n",
    "This inititalizes and starts the dask client. \n",
    "- `client.restart()` will restart the client\n",
    "- `client.close()` will close the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gloege/.conda/envs/tensorflow/lib/python3.7/site-packages/distributed/dashboard/core.py:72: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:33128</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:34152/status' target='_blank'>http://127.0.0.1:34152/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>25</li>\n",
       "  <li><b>Cores: </b>50</li>\n",
       "  <li><b>Memory: </b>269.92 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:33128' processes=25 threads=50, memory=269.92 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Intitialize the dask client\n",
    "client = Client(n_workers=25)\n",
    "# 2. Start the dask client. \n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import xarray as xr\n",
    "import xarray.ufuncs as xu\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "from scipy.stats import stats\n",
    "#from processing import processing as pr\n",
    "from skill_metrics import skill_metrics as sk\n",
    "import decompose as stl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are notebooks with function definitions\n",
    "%run _define_model_class.ipynb\n",
    "%run _define_processing_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###======================================\n",
    "### Define directories\n",
    "###====================================== \n",
    "dir_raw = '/local/data/artemis/workspace/gloege/SOCAT-LE/data/raw'\n",
    "dir_clean = '/local/data/artemis/workspace/gloege/SOCAT-LE/data/clean'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Calculate flux\n",
    "Did you run a computation already? Did you restart the client?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 25 members from MPI\n",
      "Calculating flux from 25 members from MPI\n",
      "Complete!!\n"
     ]
    }
   ],
   "source": [
    "# Directory with u10_std\n",
    "#fl_u10_std = f'{dir_clean}/ERA_interim/ERAinterim_1x1_u10-std_1982-2016.nc'\n",
    "dir_obs = '/local/data/artemis/observations'\n",
    "fl_u10_var = f'{dir_obs}/ERAinterim/processed/ERAinterim_1x1_u10-var_1982-2016.nc'\n",
    "# output directory\n",
    "dir_out = f'{dir_clean}/CO2_flux'\n",
    "\n",
    "###=================================================================\n",
    "### LE_model: ['CESM', 'GFDL', 'MPI', CanESM2]\n",
    "###=================================================================\n",
    "for LE_model in ['MPI']:\n",
    "    ###======================================\n",
    "    ### Get members from model\n",
    "    ###======================================\n",
    "    if LE_model=='CESM':\n",
    "        members=[1,2,9,10,11,12,13,14,15,16,17,18,20,21,23,24,25,30,31,34,35,101,102,103,104]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='GFDL':\n",
    "        members=[1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,22,23,26,27,28,29,30]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='MPI':\n",
    "        members=[6,9,14,20,22,24,25,27,38,43,45,46,57,60,64,70,75,77,78,80,81,83,91,95,98]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='CanESM2':\n",
    "        members=['r1r10', 'r1r6', 'r1r7', 'r1r9', 'r2r1', 'r2r2', 'r2r8', 'r3r1', 'r3r2', 'r3r4',\n",
    "                'r3r6', 'r3r7', 'r3r9', 'r4r1', 'r4r3', 'r4r5', 'r4r6', 'r4r7', 'r4r8', 'r5r1', \n",
    "                'r5r10', 'r5r2', 'r5r4', 'r5r5', 'r5r9']\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    ###======================================\n",
    "    ### Load data\n",
    "    ### client.map    --> These results live on distributed workers.\n",
    "    ### client.submit --> We can submit tasks on futures. \n",
    "    ###                   The function will go to the machine where \n",
    "    ###                   the futures are stored and run on the result \n",
    "    ###                   once it has completed.\n",
    "    ###======================================\n",
    "    print(f'Calculating flux from {n} members from {LE_model}')\n",
    "    fut = client.map(calculate_flux, \n",
    "                     tuple(np.repeat(LE_model, n)), \n",
    "                     members,\n",
    "                     tuple(np.repeat(fl_u10_var, n)), \n",
    "                     tuple(np.repeat(dir_out, n)))\n",
    "    client.gather(fut)\n",
    "    \n",
    "    # Clear up the memory\n",
    "    del fut\n",
    "    \n",
    "print('Complete!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 members from GFDL\n",
      "Calculating flux from 1 members from GFDL\n",
      "Complete!!\n"
     ]
    }
   ],
   "source": [
    "# Directory with u10_std\n",
    "dir_obs = '/local/data/artemis/observations'\n",
    "fl_u10_var = f'{dir_obs}/ERAinterim/processed/ERAinterim_1x1_u10-var_1982-2016.nc'\n",
    "#fl_u10_std = f'{dir_obs}/ERAinterim/processed/ERAinterim_1x1_u10-var_1982-2016.nc'\n",
    "\n",
    "# output directory\n",
    "dir_out = f'{dir_clean}/CO2_flux-float'\n",
    "\n",
    "###=================================================================\n",
    "### LE_model: ['CESM', 'GFDL', 'MPI', CanESM2]\n",
    "###=================================================================\n",
    "for LE_model in ['GFDL']:\n",
    "    if LE_model=='CESM':\n",
    "        members=[1,10,11,14,17,35,103]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='GFDL':\n",
    "        #members=[2,3,8,19,27,24]\n",
    "        members = [15]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "\n",
    "    ###======================================\n",
    "    ### Load data\n",
    "    ### client.map    --> These results live on distributed workers.\n",
    "    ### client.submit --> We can submit tasks on futures. \n",
    "    ###                   The function will go to the machine where \n",
    "    ###                   the futures are stored and run on the result \n",
    "    ###                   once it has completed.\n",
    "    ###======================================\n",
    "    print(f'Calculating flux from {n} members from {LE_model}')\n",
    "    fut = client.map(calculate_flux_float, \n",
    "                     tuple(np.repeat(LE_model, n)), \n",
    "                     members,\n",
    "                     tuple(np.repeat(fl_u10_var, n)), \n",
    "                     tuple(np.repeat(dir_out, n)))\n",
    "    client.gather(fut)\n",
    "    \n",
    "    # Clear up the memory\n",
    "    del fut\n",
    "    \n",
    "print('Complete!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to close the client when you're all done\n",
    "# client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calculate pCO2 Statistics\n",
    "This calculates the statistics on each member "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 25 members from CESM\n",
      "Calculating statistics for 25 member from CESM\n",
      "Loading 25 members from GFDL\n",
      "Calculating statistics for 25 member from GFDL\n",
      "Loading 25 members from CanESM2\n",
      "Calculating statistics for 25 member from CanESM2\n",
      "Loading 25 members from MPI\n",
      "Calculating statistics for 25 member from MPI\n",
      "Complete!!\n"
     ]
    }
   ],
   "source": [
    "# input directory with CO2 flux files\n",
    "# This dir_out from step 1.\n",
    "dir_in = f'{dir_clean}/pCO2_decomp_stl'\n",
    "\n",
    "# Output directory where statistics will be stored\n",
    "dir_out = f'{dir_clean}/pCO2_stats'\n",
    "\n",
    "# Print diectory in log file\n",
    "f = open(\"/home/gloege/log.stats_pco2.txt\", \"a\")\n",
    "f.write(f\"input dir : {dir_in} \\n\")\n",
    "f.write(f\"output dir : {dir_out} \\n\")\n",
    "f.close()\n",
    "\n",
    "###=================================================================\n",
    "### LE_model: ['CESM', 'GFDL', 'MPI', CanESM2]\n",
    "### model_or_recon: ['MODEL', 'SOMFFN', 'UEASI']\n",
    "###=================================================================\n",
    "for LE_model in ['CESM', 'GFDL', 'CanESM2', 'MPI']:\n",
    "    ###======================================\n",
    "    ### Get members from model\n",
    "    ###======================================\n",
    "    if LE_model=='CESM':\n",
    "        members=[1,2,9,10,11,12,13,14,15,16,17,18,20,21,23,24,25,30,31,34,35,101,102,103,104]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='GFDL':\n",
    "        members=[1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,22,23,26,27,28,29,30]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='MPI':\n",
    "        members=[6,9,14,20,22,24,25,27,38,43,45,46,57,60,64,70,75,77,78,80,81,83,91,95,98]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='CanESM2':\n",
    "        members=['r1r10', 'r1r6', 'r1r7', 'r1r9', 'r2r1', 'r2r2', 'r2r8', 'r3r1', 'r3r2', 'r3r4',\n",
    "                'r3r6', 'r3r7', 'r3r9', 'r4r1', 'r4r3', 'r4r5', 'r4r6', 'r4r7', 'r4r8', 'r5r1', \n",
    "                'r5r10', 'r5r2', 'r5r4', 'r5r5', 'r5r9']\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    ###======================================\n",
    "    ### Load data\n",
    "    ### client.map    --> These results live on distributed workers.\n",
    "    ### client.submit --> We can submit tasks on futures. \n",
    "    ###                   The function will go to the machine where \n",
    "    ###                   the futures are stored and run on the result \n",
    "    ###                   once it has completed.\n",
    "    ###======================================\n",
    "    f = open(\"/home/gloege/log.stats_pco2.txt\", \"a\")\n",
    "    f.write(f\"Calculating statistics for {n} member from {LE_model} \\n\")\n",
    "    f.close()\n",
    "    print(f'Calculating statistics for {n} member from {LE_model}')\n",
    "    fut = client.map(calculate_pco2_statistics, \n",
    "                     tuple(np.repeat(LE_model, n)), \n",
    "                     members,\n",
    "                     tuple(np.repeat(dir_in, n)),\n",
    "                     tuple(np.repeat(dir_out, n)))\n",
    "    client.gather(fut)\n",
    "    \n",
    "    # clear up the memory\n",
    "    del fut\n",
    "\n",
    "f = open(\"/home/gloege/log.stats_pco2.txt\", \"a\")\n",
    "f.write(f\"Complete!! \\n\")\n",
    "f.close()\n",
    "print('Complete!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to close the client when you're all done\n",
    "# client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculate flux statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 25 members from MPI\n",
      "Calculating statistics for 25 member from MPI\n",
      "Complete!!\n"
     ]
    }
   ],
   "source": [
    "# input directory with CO2 flux files\n",
    "# This dir_out from step 1.\n",
    "dir_in = f'{dir_clean}/CO2_flux_decomp_stl'\n",
    "\n",
    "# Output directory where statistics will be stored\n",
    "dir_out = f'{dir_clean}/CO2_flux_stats'\n",
    "\n",
    "# Print diectory in log file\n",
    "f = open(\"/home/gloege/log.stats_flux.txt\", \"a\")\n",
    "f.write(f\"input dir : {dir_in} \\n\")\n",
    "f.write(f\"output dir : {dir_out} \\n\")\n",
    "f.close()\n",
    "\n",
    "###=================================================================\n",
    "### LE_model: ['CESM', 'GFDL', 'MPI', CanESM2]\n",
    "### model_or_recon: ['MODEL', 'SOMFFN', 'UEASI']\n",
    "###=================================================================\n",
    "for LE_model in ['MPI']:\n",
    "    ###======================================\n",
    "    ### Get members from model\n",
    "    ###======================================\n",
    "    if LE_model=='CESM':\n",
    "        members=[1,2,9,10,11,12,13,14,15,16,17,18,20,21,23,24,25,30,31,34,35,101,102,103,104]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='GFDL':\n",
    "        members=[1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,22,23,26,27,28,29,30]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='MPI':\n",
    "        members=[6,9,14,20,22,24,25,27,38,43,45,46,57,60,64,70,75,77,78,80,81,83,91,95,98]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='CanESM2':\n",
    "        members=['r1r10', 'r1r6', 'r1r7', 'r1r9', 'r2r1', 'r2r2', 'r2r8', 'r3r1', 'r3r2', 'r3r4',\n",
    "                'r3r6', 'r3r7', 'r3r9', 'r4r1', 'r4r3', 'r4r5', 'r4r6', 'r4r7', 'r4r8', 'r5r1', \n",
    "                'r5r10', 'r5r2', 'r5r4', 'r5r5', 'r5r9']\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    ###======================================\n",
    "    ### Load data\n",
    "    ### client.map    --> These results live on distributed workers.\n",
    "    ### client.submit --> We can submit tasks on futures. \n",
    "    ###                   The function will go to the machine where \n",
    "    ###                   the futures are stored and run on the result \n",
    "    ###                   once it has completed.\n",
    "    ###======================================\n",
    "    f = open(\"/home/gloege/log.stats_flux.txt\", \"a\")\n",
    "    f.write(f\"Calculating statistics for {n} member from {LE_model} \\n\")\n",
    "    f.close()\n",
    "    print(f'Calculating statistics for {n} member from {LE_model}')\n",
    "    fut = client.map(calculate_flux_statistics, \n",
    "                     tuple(np.repeat(LE_model, n)), \n",
    "                     members,\n",
    "                     tuple(np.repeat(dir_in, n)),\n",
    "                     tuple(np.repeat(dir_out, n)))\n",
    "    client.gather(fut)\n",
    "    \n",
    "    # clear up the memory\n",
    "    del fut\n",
    "\n",
    "f = open(\"/home/gloege/log.stats_flux.txt\", \"a\")\n",
    "f.write(f\"Complete!! \\n\")\n",
    "f.close()\n",
    "print('Complete!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2 members from GFDL\n",
      "Calculating statistics for 2 member from GFDL\n",
      "Complete!!\n"
     ]
    }
   ],
   "source": [
    "# input directory with CO2 flux files\n",
    "# This dir_out from step 1.\n",
    "dir_in = f'{dir_clean}/CO2_flux-float_decomp_stl'\n",
    "\n",
    "# Output directory where statistics will be stored\n",
    "dir_out = f'{dir_clean}/CO2_flux-float_stats'\n",
    "\n",
    "# Print diectory in log file\n",
    "#f = open(\"/home/gloege/log.stats_flux.txt\", \"a\")\n",
    "#f.write(f\"input dir : {dir_in} \\n\")\n",
    "#f.write(f\"output dir : {dir_out} \\n\")\n",
    "#f.close()\n",
    "\n",
    "###=================================================================\n",
    "### LE_model: ['CESM', 'GFDL', 'MPI', CanESM2]\n",
    "### model_or_recon: ['MODEL', 'SOMFFN', 'UEASI']\n",
    "###=================================================================\n",
    "for LE_model in ['GFDL']:\n",
    "    ###======================================\n",
    "    if LE_model=='CESM':\n",
    "        members=[1,10,11,14,17,35,103]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='GFDL':\n",
    "        #members=[2,3,8,19,27]\n",
    "        members=[15,24] \n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='MPI':\n",
    "        members=[18,21,28,39,41,27,64]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='CanESM2':\n",
    "        members=['r1r4','r1r8','r2r3', 'r3r8','r4r10','r4r3','r5r5']\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    ###======================================\n",
    "    ### Load data\n",
    "    ### client.map    --> These results live on distributed workers.\n",
    "    ### client.submit --> We can submit tasks on futures. \n",
    "    ###                   The function will go to the machine where \n",
    "    ###                   the futures are stored and run on the result \n",
    "    ###                   once it has completed.\n",
    "    ###======================================\n",
    "    #f = open(\"/home/gloege/log.stats_flux.txt\", \"a\")\n",
    "    #f.write(f\"Calculating statistics for {n} member from {LE_model} \\n\")\n",
    "    #f.close()\n",
    "    print(f'Calculating statistics for {n} member from {LE_model}')\n",
    "    fut = client.map(calculate_flux_statistics, \n",
    "                     tuple(np.repeat(LE_model, n)), \n",
    "                     members,\n",
    "                     tuple(np.repeat(dir_in, n)),\n",
    "                     tuple(np.repeat(dir_out, n)))\n",
    "    client.gather(fut)\n",
    "    \n",
    "    # clear up the memory\n",
    "    del fut\n",
    "\n",
    "#f = open(\"/home/gloege/log.stats_flux.txt\", \"a\")\n",
    "#f.write(f\"Complete!! \\n\")\n",
    "#f.close()\n",
    "print('Complete!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:44143</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:36633/status' target='_blank'>http://127.0.0.1:36633/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>25</li>\n",
       "  <li><b>Cores: </b>50</li>\n",
       "  <li><b>Memory: </b>269.92 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:44143' processes=25 threads=50, memory=269.92 GB>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Decompose flux -- STL method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 25 members from MPI\n",
      "Decomposing 25 members from MPI\n",
      "Complete!!\n"
     ]
    }
   ],
   "source": [
    "# input directory with CO2 flux files\n",
    "# This dir_out from step 1.\n",
    "dir_in = f'{dir_clean}/CO2_flux'\n",
    "\n",
    "# Output directory where decomposition stored\n",
    "dir_out = f'{dir_clean}/CO2_flux_decomp_stl'\n",
    "\n",
    "# Print diectory in log file\n",
    "f = open(\"/home/gloege/log.decompose_flux.txt\", \"a\")\n",
    "f.write(f\"Input directory : {dir_in} \\n\")\n",
    "f.write(f\"Output directory : {dir_out} \\n\")\n",
    "f.close()\n",
    "    \n",
    "###=================================================================\n",
    "### LE_model: ['CESM', 'GFDL', 'MPI', CanESM2]\n",
    "### model_or_recon: ['MODEL', 'SOMFFN', 'UEASI']\n",
    "###=================================================================\n",
    "\n",
    "###======================================\n",
    "### model_or_recon needs to be either MODEL or SOMFFN\n",
    "###====================================== \n",
    "model_or_recon = 'SOMFFN'\n",
    "\n",
    "for LE_model in ['MPI']:\n",
    "    ###======================================\n",
    "    ### Get members from model\n",
    "    ###======================================\n",
    "    if LE_model=='CESM':\n",
    "        members=[1,2,9,10,11,12,13,14,15,16,17,18,20,21,23,24,25,30,31,34,35,101,102,103,104]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='GFDL':\n",
    "        members=[1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,22,23,26,27,28,29,30]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='MPI':\n",
    "        members=[6,9,14,20,22,24,25,27,38,43,45,46,57,60,64,70,75,77,78,80,81,83,91,95,98]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='CanESM2':\n",
    "        members=['r1r10', 'r1r6', 'r1r7', 'r1r9', 'r2r1', 'r2r2', 'r2r8', 'r3r1', 'r3r2', 'r3r4',\n",
    "                'r3r6', 'r3r7', 'r3r9', 'r4r1', 'r4r3', 'r4r5', 'r4r6', 'r4r7', 'r4r8', 'r5r1', \n",
    "                'r5r10', 'r5r2', 'r5r4', 'r5r5', 'r5r9']\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    ###======================================\n",
    "    ### Load data\n",
    "    ### client.map    --> These results live on distributed workers.\n",
    "    ### client.submit --> We can submit tasks on futures. \n",
    "    ###                   The function will go to the machine where \n",
    "    ###                   the futures are stored and run on the result \n",
    "    ###                   once it has completed.\n",
    "    ###======================================\n",
    "    # Print diectory in log file\n",
    "    f = open(\"/home/gloege/log.decompose_flux.txt\", \"a\")\n",
    "    f.write(f\"Decomposing {n} members from {LE_model} \\n\")\n",
    "    f.close()\n",
    "    print(f\"Decomposing {n} members from {LE_model}\")\n",
    "    \n",
    "    # run decompose_flux function\n",
    "    fut = client.map(decompose_flux, \n",
    "                     tuple(np.repeat(LE_model, n)), \n",
    "                     members, \n",
    "                     tuple(np.repeat(model_or_recon, n)),\n",
    "                     tuple(np.repeat(dir_in, n)),\n",
    "                     tuple(np.repeat(dir_out, n)))\n",
    "    client.gather(fut)\n",
    "    \n",
    "    del fut\n",
    "    \n",
    "# Print diectory in log file\n",
    "f = open(\"/home/gloege/log.decompose_flux.txt\", \"a\")\n",
    "f.write(f\"Complete!! \\n\")\n",
    "f.close()\n",
    "print('Complete!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2 members from GFDL\n",
      "Decomposing 2 members from GFDL\n",
      "Complete!!\n"
     ]
    }
   ],
   "source": [
    "# input directory with CO2 flux files\n",
    "# This dir_out from step 1.\n",
    "dir_in = f'{dir_clean}/CO2_flux-float'\n",
    "\n",
    "# Output directory where decomposition stored\n",
    "dir_out = f'{dir_clean}/CO2_flux-float_decomp_stl'\n",
    "\n",
    "# Print diectory in log file\n",
    "#f = open(\"/home/gloege/log.decompose_flux.txt\", \"a\")\n",
    "#f.write(f\"Input directory : {dir_in} \\n\")\n",
    "#f.write(f\"Output directory : {dir_out} \\n\")\n",
    "#f.close()\n",
    "    \n",
    "###=================================================================\n",
    "### LE_model: ['CESM', 'GFDL', 'MPI', CanESM2]\n",
    "### model_or_recon: ['MODEL', 'SOMFFN', 'UEASI']\n",
    "###=================================================================\n",
    "\n",
    "###======================================\n",
    "### model_or_recon needs to be either MODEL or SOMFFN\n",
    "###====================================== \n",
    "model_or_recon = 'SOMFFN'\n",
    "\n",
    "for LE_model in ['GFDL']:\n",
    "    ###======================================\n",
    "    ### Get members from model\n",
    "    ###======================================\n",
    "    if LE_model=='CESM':\n",
    "        members=[1,10,11,14,17,35,103]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='GFDL':\n",
    "        #members=[2,3,8,19,27]\n",
    "        members=[15,24] \n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='MPI':\n",
    "        members=[18,21,28,39,41,27,64]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='CanESM2':\n",
    "        members=['r1r4','r1r8','r2r3', 'r3r8','r4r10','r4r3','r5r5']\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    ###======================================\n",
    "    ### Load data\n",
    "    ### client.map    --> These results live on distributed workers.\n",
    "    ### client.submit --> We can submit tasks on futures. \n",
    "    ###                   The function will go to the machine where \n",
    "    ###                   the futures are stored and run on the result \n",
    "    ###                   once it has completed.\n",
    "    ###======================================\n",
    "    # Print diectory in log file\n",
    "    #f = open(\"/home/gloege/log.decompose_flux.txt\", \"a\")\n",
    "    #f.write(f\"Decomposing {n} members from {LE_model} \\n\")\n",
    "    #f.close()\n",
    "    print(f\"Decomposing {n} members from {LE_model}\")\n",
    "    \n",
    "    # run decompose_flux function\n",
    "    fut = client.map(decompose_flux, \n",
    "                     tuple(np.repeat(LE_model, n)), \n",
    "                     members, \n",
    "                     tuple(np.repeat(model_or_recon, n)),\n",
    "                     tuple(np.repeat(dir_in, n)),\n",
    "                     tuple(np.repeat(dir_out, n)))\n",
    "    client.gather(fut)\n",
    "    \n",
    "    del fut\n",
    "\n",
    "# Print diectory in log file\n",
    "#f = open(\"/home/gloege/log.decompose_flux.txt\", \"a\")\n",
    "#f.write(f\"Complete!! \\n\")\n",
    "#f.close()\n",
    "print('Complete!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Decompose pCO2 -- STL\n",
    "This decomposes pCO2 using the STL method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:33128</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:34152/status' target='_blank'>http://127.0.0.1:34152/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>25</li>\n",
       "  <li><b>Cores: </b>50</li>\n",
       "  <li><b>Memory: </b>269.92 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:33128' processes=25 threads=50, memory=269.92 GB>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 25 members from CESM\n",
      "Decomposing 25 members from CESM\n",
      "Loading 25 members from GFDL\n",
      "Decomposing 25 members from GFDL\n"
     ]
    }
   ],
   "source": [
    "###=================================================================\n",
    "### LE_model: ['CESM', 'GFDL', 'MPI', CanESM2]\n",
    "### model_or_recon: ['MODEL', 'SOMFFN', 'UEASI']\n",
    "###=================================================================\n",
    "\n",
    "# Output directory where decomposition stored\n",
    "dir_out = f'{dir_clean}/pCO2_decomp_stl'\n",
    "\n",
    "# Print diectory in log file\n",
    "f = open(\"/home/gloege/log.decompose_pco2.txt\", \"a\")\n",
    "f.write(f\"Output directory : {dir_out} \\n\")\n",
    "f.close()\n",
    "    \n",
    "###======================================\n",
    "### model_or_recon needs to be either MODEL or SOMFFN\n",
    "###====================================== \n",
    "model_or_recon = 'MODEL'\n",
    "\n",
    "for LE_model in ['CESM', 'GFDL', 'CanESM2', 'MPI']:\n",
    "    ###======================================\n",
    "    ### Get members from model\n",
    "    ###======================================\n",
    "    if LE_model=='CESM':\n",
    "        members=[1,2,9,10,11,12,13,14,15,16,17,18,20,21,23,24,25,30,31,34,35,101,102,103,104]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='GFDL':\n",
    "        members=[1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,22,23,26,27,28,29,30]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='MPI':\n",
    "        members=[6,9,14,20,22,24,25,27,38,43,45,46,57,60,64,70,75,77,78,80,81,83,91,95,98]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='CanESM2':\n",
    "        members=['r1r10', 'r1r6', 'r1r7', 'r1r9', 'r2r1', 'r2r2', 'r2r8', 'r3r1', 'r3r2', 'r3r4',\n",
    "                'r3r6', 'r3r7', 'r3r9', 'r4r1', 'r4r3', 'r4r5', 'r4r6', 'r4r7', 'r4r8', 'r5r1', \n",
    "                'r5r10', 'r5r2', 'r5r4', 'r5r5', 'r5r9']\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    ###======================================\n",
    "    ### Load data\n",
    "    ### client.map    --> These results live on distributed workers.\n",
    "    ### client.submit --> We can submit tasks on futures. \n",
    "    ###                   The function will go to the machine where \n",
    "    ###                   the futures are stored and run on the result \n",
    "    ###                   once it has completed.\n",
    "    ###======================================\n",
    "    ## Print to log file\n",
    "    f = open(\"/home/gloege/log.decompose_pco2.txt\", \"a\")\n",
    "    f.write(f\"Decomposing {n} members from {LE_model} \\n\")\n",
    "    f.close()\n",
    "    print(f'Decomposing {n} members from {LE_model}')\n",
    "    \n",
    "    ## Run the decompose_pco2 function\n",
    "    fut = client.map(decompose_pco2, \n",
    "                     tuple(np.repeat(LE_model, n)), \n",
    "                     members, \n",
    "                     tuple(np.repeat(model_or_recon, n)),\n",
    "                     tuple(np.repeat(dir_out, n)))\n",
    "    client.gather(fut)\n",
    "    \n",
    "    del fut\n",
    "    \n",
    "print('Complete!!')\n",
    "f = open(\"/home/gloege/log.decompose_pco2.txt\", \"a\")\n",
    "f.write(f\"Complete! \\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input directory with CO2 flux files\n",
    "# This dir_out from step 1.\n",
    "dir_in = f'{dir_clean}/CO2_flux'\n",
    "\n",
    "# Output directory where decomposition stored\n",
    "dir_out = f'{dir_clean}/CO2_flux_decomp'\n",
    "\n",
    "###=================================================================\n",
    "### LE_model: ['CESM', 'GFDL', 'MPI', CanESM2]\n",
    "### model_or_recon: ['MODEL', 'SOMFFN', 'UEASI']\n",
    "###=================================================================\n",
    "\n",
    "###======================================\n",
    "### model_or_recon needs to be either MODEL or SOMFFN\n",
    "###====================================== \n",
    "model_or_recon = 'MODEL'\n",
    "\n",
    "for LE_model in ['CESM', 'GFDL', 'CanESM2']:\n",
    "    ###======================================\n",
    "    ### Get members from model\n",
    "    ###======================================\n",
    "    if LE_model=='CESM':\n",
    "        members=[1,2,9,10,11,12,13,14,15,16,17,18,20,21,23,24,25,30,31,34,35,101,102,103,104]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='GFDL':\n",
    "        members=[1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,22,23,26,27,28,29,30]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='MPI':\n",
    "        members=[6,9,14,20,22,24,25,27,38,43,45,46,57,60,64,70,75,77,78,80,81,83,91,95,98]\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    if LE_model=='CanESM2':\n",
    "        members=['r1r10', 'r1r6', 'r1r7', 'r1r9', 'r2r1', 'r2r2', 'r2r8', 'r3r1', 'r3r2', 'r3r4',\n",
    "                'r3r6', 'r3r7', 'r3r9', 'r4r1', 'r4r3', 'r4r5', 'r4r6', 'r4r7', 'r4r8', 'r5r1', \n",
    "                'r5r10', 'r5r2', 'r5r4', 'r5r5', 'r5r9']\n",
    "        n = len(members)\n",
    "        print(f'Loading {n} members from {LE_model}')\n",
    "\n",
    "    ###======================================\n",
    "    ### Load data\n",
    "    ### client.map    --> These results live on distributed workers.\n",
    "    ### client.submit --> We can submit tasks on futures. \n",
    "    ###                   The function will go to the machine where \n",
    "    ###                   the futures are stored and run on the result \n",
    "    ###                   once it has completed.\n",
    "    ###======================================\n",
    "    print(f'Decomposing {n} members from {LE_model}')\n",
    "    fut = client.map(decompose_flux, \n",
    "                     tuple(np.repeat(LE_model, n)), \n",
    "                     members, \n",
    "                     tuple(np.repeat(model_or_recon, n)),\n",
    "                     tuple(np.repeat(dir_in, n)),\n",
    "                     tuple(np.repeat(dir_out, n)))\n",
    "    client.gather(fut)\n",
    "    \n",
    "    del fut\n",
    "    \n",
    "print('Complete!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
